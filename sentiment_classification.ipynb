{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the Data\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         ['neutral']\n",
      "1         ['neutral']\n",
      "2        ['positive']\n",
      "3        ['positive']\n",
      "4        ['positive']\n",
      "5        ['positive']\n",
      "6        ['positive']\n",
      "7         ['neutral']\n",
      "8        ['positive']\n",
      "9        ['positive']\n",
      "10       ['positive']\n",
      "11        ['neutral']\n",
      "12        ['neutral']\n",
      "13        ['neutral']\n",
      "14       ['positive']\n",
      "15       ['positive']\n",
      "16       ['positive']\n",
      "17       ['positive']\n",
      "18        ['neutral']\n",
      "19        ['neutral']\n",
      "20       ['positive']\n",
      "21        ['neutral']\n",
      "22        ['neutral']\n",
      "23       ['positive']\n",
      "24       ['positive']\n",
      "25       ['positive']\n",
      "26        ['neutral']\n",
      "27       ['positive']\n",
      "28        ['neutral']\n",
      "29       ['negative']\n",
      "             ...     \n",
      "50829    ['positive']\n",
      "50830     ['neutral']\n",
      "50831     ['neutral']\n",
      "50832    ['positive']\n",
      "50833     ['neutral']\n",
      "50834     ['neutral']\n",
      "50835    ['positive']\n",
      "50836     ['neutral']\n",
      "50837    ['negative']\n",
      "50838     ['neutral']\n",
      "50839     ['neutral']\n",
      "50840     ['neutral']\n",
      "50841    ['positive']\n",
      "50842     ['neutral']\n",
      "50843     ['neutral']\n",
      "50844     ['neutral']\n",
      "50845     ['neutral']\n",
      "50846     ['neutral']\n",
      "50847    ['positive']\n",
      "50848     ['neutral']\n",
      "50849    ['negative']\n",
      "50850    ['positive']\n",
      "50851     ['neutral']\n",
      "50852    ['positive']\n",
      "50853     ['neutral']\n",
      "50854    ['positive']\n",
      "50855    ['positive']\n",
      "50856     ['neutral']\n",
      "50857    ['positive']\n",
      "50858    ['positive']\n",
      "Name: Sentiment, Length: 50873, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sarang/Downloads/btc_prediction_project/BTC_tweets_daily_example.csv')\n",
    "print(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50873"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    if type(text) is str:\n",
    "        text = text.lower() # lowercase text\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", str(text))\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['Tweet'] = df['Tweet'].apply(clean_text)\n",
    "df['Tweet'].apply(lambda x: len(x.split(' '))).sum()\n",
    "df['Sentiment'] = df['Sentiment'].apply(clean_text)\n",
    "df['Sentiment'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         neutral\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        positive\n",
       "5        positive\n",
       "6        positive\n",
       "7         neutral\n",
       "8        positive\n",
       "9        positive\n",
       "10       positive\n",
       "11        neutral\n",
       "12        neutral\n",
       "13        neutral\n",
       "14       positive\n",
       "15       positive\n",
       "16       positive\n",
       "17       positive\n",
       "18        neutral\n",
       "19        neutral\n",
       "20       positive\n",
       "21        neutral\n",
       "22        neutral\n",
       "23       positive\n",
       "24       positive\n",
       "25       positive\n",
       "26        neutral\n",
       "27       positive\n",
       "28        neutral\n",
       "29       negative\n",
       "           ...   \n",
       "50829    positive\n",
       "50830     neutral\n",
       "50831     neutral\n",
       "50832    positive\n",
       "50833     neutral\n",
       "50834     neutral\n",
       "50835    positive\n",
       "50836     neutral\n",
       "50837    negative\n",
       "50838     neutral\n",
       "50839     neutral\n",
       "50840     neutral\n",
       "50841    positive\n",
       "50842     neutral\n",
       "50843     neutral\n",
       "50844     neutral\n",
       "50845     neutral\n",
       "50846     neutral\n",
       "50847    positive\n",
       "50848     neutral\n",
       "50849    negative\n",
       "50850    positive\n",
       "50851     neutral\n",
       "50852    positive\n",
       "50853     neutral\n",
       "50854    positive\n",
       "50855    positive\n",
       "50856     neutral\n",
       "50857    positive\n",
       "50858    positive\n",
       "Name: Sentiment, Length: 50873, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         neutral\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        positive\n",
       "5        positive\n",
       "6        positive\n",
       "7         neutral\n",
       "8        positive\n",
       "9        positive\n",
       "10       positive\n",
       "11        neutral\n",
       "12        neutral\n",
       "13        neutral\n",
       "14       positive\n",
       "15       positive\n",
       "16       positive\n",
       "17       positive\n",
       "18        neutral\n",
       "19        neutral\n",
       "20       positive\n",
       "21        neutral\n",
       "22        neutral\n",
       "23       positive\n",
       "24       positive\n",
       "25       positive\n",
       "26        neutral\n",
       "27       positive\n",
       "28        neutral\n",
       "29       negative\n",
       "           ...   \n",
       "50829    positive\n",
       "50830     neutral\n",
       "50831     neutral\n",
       "50832    positive\n",
       "50833     neutral\n",
       "50834     neutral\n",
       "50835    positive\n",
       "50836     neutral\n",
       "50837    negative\n",
       "50838     neutral\n",
       "50839     neutral\n",
       "50840     neutral\n",
       "50841    positive\n",
       "50842     neutral\n",
       "50843     neutral\n",
       "50844     neutral\n",
       "50845     neutral\n",
       "50846     neutral\n",
       "50847    positive\n",
       "50848     neutral\n",
       "50849    negative\n",
       "50850    positive\n",
       "50851     neutral\n",
       "50852    positive\n",
       "50853     neutral\n",
       "50854    positive\n",
       "50855    positive\n",
       "50856     neutral\n",
       "50857    positive\n",
       "50858    positive\n",
       "Name: Sentiment, Length: 50873, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tags = ['positive','negative','neutral']\n",
    "df['Sentiment'] = df['Sentiment'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39739    https co xugcgghvsv sohu ico solution agency a...\n",
      "27280    rt airdropkitties register amp go long short e...\n",
      "27439    vlc airdrop get free token vlc https co awzljs...\n",
      "23463    rt bethereumteam successful launch bounty camp...\n",
      "45508    dandoncrypto bitcoin btg bitcoin gold go gaini...\n",
      "24965    could bitcoin gold benefit weakness stock mark...\n",
      "31633    grockrecords bitcoin gold bitcoin gold become ...\n",
      "45563    bitcoin price usd blx https co ubgkl pwso http...\n",
      "46040    rt eiracube square seeks bitlicense bring bitc...\n",
      "2191     rt bethereumteam smart contracts read technolo...\n",
      "45049    bitcoin bitcoin cash ethereum bitcoin ethereum...\n",
      "10092    moneyandpower bitcoin better money https co ug...\n",
      "24799    check list trusted cloud mining services opini...\n",
      "3494     rt randolphmlny bitcoin crypto blockchain aird...\n",
      "25926    rt btccloud official bitcoin cloud airdrop htt...\n",
      "45371    name dadi symbol dadi hour change price rank t...\n",
      "22223              rt rnr bitcoin care https co oqvdiutmrk\n",
      "33433    rt alex danco report card posted publicly ever...\n",
      "28245    crypt snews ohnickel akshay mittal gcruzn elle...\n",
      "43707    rt aeternumcoin watch aeternumcoin token sale ...\n",
      "18517    book cyberwar china new type war sa https co d...\n",
      "29416    zebpay champcoin potential next bitcoin techno...\n",
      "29221    dutch court finds bitcoin legitimate transfera...\n",
      "20069    rt bethereumteam already correctly guessed rea...\n",
      "26232    rt theethercash https co cb tz qko airdrop fol...\n",
      "5541     rt coinsairdrops bitcoin satoshi crypto blockc...\n",
      "13160             start bitcoin mining https co rotfislxxq\n",
      "13683    rt bethereumteam seen animated motion pictures...\n",
      "47278    book sheds light major crime radar https co hs...\n",
      "5012     rt bethereumteam checkout interview team feel ...\n",
      "                               ...                        \n",
      "4548     rt airpod project airpod project sweep away co...\n",
      "34340    bitcoin ethereum litecoin buy online bank tran...\n",
      "34351    rt crypto rand giving away participate need fo...\n",
      "44782    signalsnetwork signals futuristic marketplace ...\n",
      "6882     hardware bitcoin wallet get trezor eur https c...\n",
      "22167    rt shift cash watch new interview https co jps...\n",
      "25743    rt harddrivemag man invested early bitcoin wis...\n",
      "17134    rt btccloud official bitcoin cloud airdrop htt...\n",
      "48568    rt cloudminingx use code hf bday purchase get ...\n",
      "21365    rt bitschoolai find smart contract address nav...\n",
      "30451    rt joefloccari breaking city atlanta atlanta p...\n",
      "6988     rt cyberdomain dns security hacking defending ...\n",
      "9123     rt bitcoinyuri next bull run make lot people t...\n",
      "6205     rt drdenagrayson breaking rockin rod rosenstei...\n",
      "4402     rt realairdrop hot airdrop faxport airdropping...\n",
      "22894    untangling bitcoin russell yanofsky taking apa...\n",
      "11124    rt btccloud official bitcoin cloud airdrop htt...\n",
      "6233     proffaustus bitcoin bubble mr wright sell bitc...\n",
      "6253     name triggers symbol trig hour change price ra...\n",
      "40752    rt setcoinsale setcoin advisor david drake bit...\n",
      "9861     rt btccloud official bitcoin cloud airdrop htt...\n",
      "29108    vittagam bitcoin gold bitcoin gold become popu...\n",
      "2990     rt rogerkver high fees unreliable transactions...\n",
      "12532    rt witchaindev airdrop wit tokens value airdro...\n",
      "45564    rt airdropkitty technical analysis suggests bi...\n",
      "6739     rt nfrisbie ok internet need help let break wo...\n",
      "1389     cryptocurrency news today decoin agrocoin sga ...\n",
      "28787    russian fintech association unveil blockchain ...\n",
      "23718    p p solutions foundation company goal creating...\n",
      "5262     li explosi n de bitcoin dukascopy swiss forex ...\n",
      "Name: Tweet, Length: 10175, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Conversion of text into Feature vectors\n",
    "\n",
    "X = df.Tweet\n",
    "y = df.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier for Multinomial Models\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('Naive Bayes accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#print(classification_report(y_test, y_pred,target_names=my_tags))\n",
    "naivebayes_accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'naive_bayes_model.sav'\n",
    "pickle.dump(nb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('Linear SVC accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "linearsvc_accuracy = accuracy_score(y_pred, y_test)\n",
    "#print(classification_report(y_test, y_pred,target_names=my_tags))\n",
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'svm_model.sav'\n",
    "pickle.dump(sgd, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clf1 = nb\n",
    "clf2 = sgd\n",
    "\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "\n",
    "clf3 = logreg.fit(X_train, y_train)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('nb', clf1),('log', clf3)], voting='hard')\n",
    "eclf1.fit(X_train, y_train)\n",
    "y_pred = eclf1.predict(X_test)\n",
    "\n",
    "print('Hybrid Classifier %s' % accuracy_score(y_pred, y_test))\n",
    "log_nb_accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "import pickle\n",
    "filename = 'hybrid_model.sav'\n",
    "pickle.dump(clf3, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison chart of different accuracies\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "N = 1\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.5       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "\n",
    "linearsvc_percentage = (linearsvc_accuracy) * 100\n",
    "rects1 = ax.bar(ind, linearsvc_percentage, width, color='r')\n",
    "\n",
    "niavebayes_percentage = naivebayes_accuracy * 100\n",
    "rects2 = ax.bar(ind+width, niavebayes_percentage, width, color='y')\n",
    "\n",
    "logisticregression_nb_percentage = log_nb_accuracy * 100\n",
    "rects3 = ax.bar(ind+width*2, logisticregression_nb_percentage, width, color='k')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_xlabel('Classifier')\n",
    "ax.set_ylabel('Accuracy (by percentage)')\n",
    "ax.set_title('Accuracy by Diff Classifiers')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('') )\n",
    "\n",
    "ax.legend( (rects1[0], rects2[0],rects3[0]), ('Linear SVC', 'Naive Bayes', 'NB + LogReg'), bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "\n",
    "def autolabel(rects):\n",
    "\t# attach some text labels\n",
    "\tfor rect in rects:\n",
    "\t\theight = rect.get_height()\n",
    "\t\tax.text(rect.get_x()+rect.get_width()/2., 1.02*height, '%10.2f' % float(height),\n",
    "\t\t\t\tha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
